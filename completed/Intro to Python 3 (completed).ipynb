{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Intro to Python 3\n",
    "### Scraping data\n",
    "\n",
    "While code-free tools are handy in a pinch, scripts written in Python or another language are more flexible and adaptable. They can also run automatically in the background on a schedule. Also, you don't have to worry about a service or a tool ever disappearing, making all your hard work for naught.\n",
    "\n",
    "The steps we will take together in Python to make this happen:\n",
    "\n",
    "1. Fetch a web page\n",
    "2. Make the HTML into something Python can navigate\n",
    "3. Isolate a table\n",
    "4. Loop through each row (and cell), extracting the text\n",
    "5. Write all the data to a CSV\n",
    "\n",
    "Instead of just powering through and hoping for the best, we'll mess around a bit as we go so you can see what each step is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import modules to facilitate the scrape\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodecsv as csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`requests` is great at playing web browser. For more information, check out the [full documentation](http://docs.python-requests.org/en/master/).\n",
    "\n",
    "```python\n",
    "requests.get('some URL')\n",
    "# navigates to a site and sends you the response\n",
    "\n",
    "response.content\n",
    "# a way requests serves up the page's source code (HTML)\n",
    "```\n",
    "\n",
    "We are going to be getting data on nuclear reactors operating in the U.S.: http://www.nrc.gov/reactors/operating/list-power-reactor-units.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fetch the contents of webpage with requests\n",
    "url = \"http://www.nrc.gov/reactors/operating/list-power-reactor-units.html\"\n",
    "main_page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let BeautifulSoup parse the content of that page\n",
    "soup = BeautifulSoup(main_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Two key ways to isolate specific sections of the web page in question with `BeautifulSoup`:\n",
    "```python\n",
    "soup.find('some HTML tag')\n",
    "# returns the first tag that matches\n",
    "\n",
    "soup.find_all('some HTML tag')\n",
    "# returns a list of all tags that match\n",
    "```\n",
    "\n",
    "(`BeautifulSoup` also has [detailed documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for the various ways in which it can parse HTML and XML.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# snip out the table and pass it to a new variable\n",
    "reactors_table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print reactor_table to verify we have the right thing\n",
    "print(reactors_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use .find_all to create a list of rows in the table\n",
    "reactor_table_rows = reactors_table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# isolate the second row and print it\n",
    "ex_row = reactor_table_rows[1]\n",
    "print(ex_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One of our table's rows, with a little shading and indentation:\n",
    "\n",
    "```html\n",
    "<tr valign=\"top\">\n",
    "    <td scope=\"row\"><a href=\"/info-finder/reactors/ano1.html\">Arkansas Nuclear 1</a><br/>05000313</td>\n",
    "    <td align=\"center\">DPR-51</td>\n",
    "    <td>PWR</td>\n",
    "    <td>6 miles WNW of Russellville,  AR</td>\n",
    "    <td>Entergy Nuclear Operations, Inc.</td>\n",
    "    <td align=\"middle\">4</td>\n",
    "</tr>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use .find_all again to generate a list of the row's cells and return it\n",
    "cells = ex_row.find_all('td')\n",
    "cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "BeautifulSoup has a few other methods that are helpful for extracting the information _inside_ of tags:\n",
    "```python\n",
    "soup.contents\n",
    "# breaks up everything in a tag into a fresh list (useful when you have more than text in a cell)\n",
    "\n",
    "soup.text\n",
    "# returns the text in a tag as a string\n",
    "\n",
    "soup.get('some attribute')\n",
    "# returns the attribute (useful for getting URLs, for example)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's break apart the contents of the first column: the name, the link and the docket number\n",
    "print(cells[0].contents[0].text)\n",
    "print(cells[0].contents[0].get('href'))\n",
    "print(cells[0].contents[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK, now for the tricky part. We need to through each row in the table and extract the contents of each cell. We'll set up an empty list beforehand and append each row of extracted data to it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make an empty list to hold the data\n",
    "scraped = []\n",
    "\n",
    "# a for loop is going to take us through every row in the table EXCEPT the header\n",
    "# combining two steps: the list it pulls from will be greated by a .find_all for 'tr' tags\n",
    "for row in reactors_table.find_all('tr')[1:]:\n",
    "    \n",
    "    # .find_all 'td' tags in the row and put them into a variable\n",
    "    cells = row.find_all('td')\n",
    "    \n",
    "    # extract the cell contents\n",
    "    reactor_name = cells[0].contents[0].text\n",
    "    link = 'http://www.nrc.gov' + cells[0].contents[0].get('href')\n",
    "    docket = cells[0].contents[2]\n",
    "    license = cells[1].text\n",
    "    reactor_type = cells[2].text\n",
    "    location = cells[3].text\n",
    "    owner = cells[4].text\n",
    "    region = cells[5].text\n",
    "    \n",
    "    # append the collected data to the empty list\n",
    "    scraped.append([reactor_name, link, docket, license, reactor_type, location, owner, region])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's been great, of course, but now we need to get all the data out of the script and into a usable format. We're using `unicodecsv`, which glosses over Python 2's shortcomings for dealing with the unicode characters that exist in this table, letting us write them with ease.\n",
    "\n",
    "```python\n",
    "open('some file', 'read/write/append?')\n",
    "# open a file and tell Python how to treat it\n",
    "\n",
    "csv.writer('some file we opened')\n",
    "# make a writer object that can move information from your script to a file in CSV form\n",
    "\n",
    "writer_obj.writerow('some list of strings')\n",
    "# write a single row\n",
    "\n",
    "writer_obj.writerows('some list of lists of strings')\n",
    "# write a bunch of rows\n",
    "```\n",
    "\n",
    "`unicodecsv` works a lot like the standard `csv` Python module, so check out [the documentation](https://docs.python.org/2/library/csv.html) for more examples of how it all works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# open a file and write our data to it\n",
    "with open('reactor_data.csv', 'wb') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['reactor_name', 'link', 'docket', 'license', 'reactor_type', 'location', 'owner', 'region'])\n",
    "    writer.writerows(scraped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
